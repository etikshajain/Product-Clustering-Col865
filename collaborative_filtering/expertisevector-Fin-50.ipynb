{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import implicit \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import glob\n",
    "import time\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import PercentFormatter\n",
    "import os\n",
    "import statistics\n",
    "from scipy.sparse import csr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.environ[\"OPENBLAS_NUM_THREADS\"] = \"1\"\n",
    "#os.environ[\"GOTO_NUM_THREADS\"] = \"1\"\n",
    "#os.environ[\"OMP_NUM_THREADS\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('/media/root/data/swiggy/flipkart/data2/ppv2.csv')\n",
    "print(\"Data read.\")\n",
    "#data[data['count'] > 500] = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First creating required sparse csr matrix\n",
    "import scipy\n",
    "products = data.product_id.unique()\n",
    "accounts = data.account_id_enc.unique()\n",
    "\n",
    "print(len(products))\n",
    "print(len(accounts))\n",
    "\n",
    "prod_to_int = {}\n",
    "acc_to_int = {}\n",
    "int_to_prod = {}\n",
    "int_to_acc = {}\n",
    "\n",
    "count=0\n",
    "for prod in products:\n",
    "    prod_to_int[prod] = count\n",
    "    int_to_prod[count] = prod\n",
    "    count += 1\n",
    "\n",
    "count=0\n",
    "for acc in accounts:\n",
    "    acc_to_int[acc] = count\n",
    "    int_to_acc[count] = acc\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['count'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "print(\"Preprocessing started\")\n",
    "df_acc_to_int = pd.DataFrame(acc_to_int.items(), columns=['account_id', 'account_index'])\n",
    "df_prod_to_int = pd.DataFrame(prod_to_int.items(), columns=['product_id', 'product_index'])\n",
    "data_userIdx = pd.merge(data, df_acc_to_int, left_on=['account_id_enc'], right_on = ['account_id'])\n",
    "data_userIdx_productIdx = pd.merge(data_userIdx, df_prod_to_int, left_on=['product_id'], right_on = ['product_id'])\n",
    "rows = np.array(data_userIdx_productIdx['account_index'])\n",
    "cols = np.array(data_userIdx_productIdx['product_index'])\n",
    "values = np.array(data_userIdx_productIdx['count'])\n",
    "print(\"Preprocessing done.\")\n",
    "print(\"Time taken ->\", time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create CSR matrix\n",
    "sparseMatrix = csr_matrix((values, (cols, rows)), shape = ( len(products),len(accounts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ALS wont work well enough.\n",
    "matrix_size = sparseMatrix.shape[0]*sparseMatrix.shape[1] # Number of possible interactions in the matrix\n",
    "num_purchases = len(sparseMatrix.nonzero()[0]) # Number of items interacted with\n",
    "sparsity = 100*(1 - (num_purchases/matrix_size))\n",
    "print(sparsity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = implicit.als.AlternatingLeastSquares(factors=50)\n",
    "\n",
    "model.fit(sparseMatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_vecs = model.item_factors\n",
    "user_vecs = model.user_factors\n",
    "print('Shape of item vector matrix : ', item_vecs.shape)\n",
    "print('Shape of User vector matrix : ', user_vecs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('user_feature.npy',user_vecs)\n",
    "np.save('item_feature.npy',item_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from kneed import KneeLocator\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_k(df, increment=0, decrement=0):\n",
    "    \"\"\"Find the optimum k clusters\"\"\"\n",
    "    \n",
    "    df_norm = df\n",
    "    sse = {}\n",
    "    \n",
    "    for k in range(1, 20):\n",
    "        print(\"Cluster no: \",k)\n",
    "        kmeans = KMeans(n_clusters=k, random_state=1)\n",
    "        kmeans.fit(df_norm)\n",
    "        sse[k] = kmeans.inertia_\n",
    "    \n",
    "    kn = KneeLocator(x=list(sse.keys()), \n",
    "                 y=list(sse.values()), \n",
    "                 curve='convex', \n",
    "                 direction='decreasing')\n",
    "    k = kn.knee + increment - decrement\n",
    "    return k\n",
    "\n",
    "k = find_k(user_vecs)\n",
    "print(\"Ideal no of clusters is: \",k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.load(\"user_feature.npy\")\n",
    "start_time = time.time()\n",
    "print(\"Clustering started\")\n",
    "kmeans = KMeans(n_clusters=10,random_state=0).fit(x)\n",
    "\n",
    "np.save('labels.npy',kmeans.labels_)\n",
    "np.save('centers.npy',kmeans.cluster_centers_)\n",
    "print(\"Clustering done.\")\n",
    "print(\"Time taken ->\", time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = kmeans.labels_\n",
    "centers = kmeans.cluster_centers_\n",
    "print(labels.shape)\n",
    "(unique, counts) = np.unique(labels, return_counts=True)\n",
    "print(labels.shape)\n",
    "frequencies = np.asarray((unique, counts)).T\n",
    "print(frequencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shopsy_dataset = pd.read_csv('/media/root/data/swiggy/flipkart/data2/reseller_profile.csv')\n",
    "print(shopsy_dataset['s.account_id_enc'].nunique())\n",
    "print(shopsy_dataset['s.product_id'].nunique())\n",
    "print(shopsy_dataset.shape[0])\n",
    "\n",
    "shopsy_user_product = shopsy_dataset.groupby(['s.account_id_enc','s.product_id'],as_index=False).agg({'s.order_item_id_enc':'count'})\n",
    "print(\"user product combination in shopsy\", shopsy_user_product.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shopsy_user_product_encode_temp = pd.merge(shopsy_user_product, df_acc_to_int, left_on=['s.account_id_enc'], right_on = ['account_id'])\n",
    "shopsy_user_product_encode = pd.merge(shopsy_user_product_encode_temp, df_prod_to_int, left_on=['s.product_id'], right_on = ['product_id'])\n",
    "shopsy_click_users = pd.merge(data_userIdx_productIdx, shopsy_user_product_encode, right_on=['account_index','product_index'], left_on = ['account_index','product_index'],how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import sample\n",
    "\n",
    "def intersection(lst1, lst2):\n",
    "    store = list(set(lst1) & set(lst2))\n",
    "    return len(store)\n",
    "\n",
    "mean_items_bought = 0\n",
    "user_idx = shopsy_click_users['account_index'].unique()\n",
    "print(\"Sampling done\")\n",
    "user_idx = sample(list(user_idx),500)\n",
    "start_time = time.time()\n",
    "for user in user_idx:\n",
    "    count = count+1\n",
    "    item_interest = np.dot(item_vecs,x[user].reshape(-1, 1)).reshape(-1)\n",
    "    pred_items = (-item_interest).argsort()[:20]\n",
    "    actual_items = shopsy_click_users[shopsy_click_users['account_index']==user]\n",
    "    items_bought = actual_items['product_index'].unique()\n",
    "    frac_actually_bought = intersection(items_bought,pred_items)/20\n",
    "    mean_items_bought += frac_actually_bought \n",
    "mean_items_bought = mean_items_bought/len(user_idx)\n",
    "print(\"Mean item fraction brought: \",mean_items_bought)\n",
    "print(\"Time taken ->\", time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "click_productid_category = data.groupby(['product_id','cms_vertical'],as_index=False).agg({'count':'sum'})\n",
    "click_productid_category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "click_productid_category_productidx = pd.merge(click_productid_category, df_prod_to_int, left_on=['product_id'], right_on = ['product_id'])\n",
    "click_productid_category_productidx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fin_dataset = click_productid_category_productidx.sort_values(['product_index'])\n",
    "fin_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fin_dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import sample\n",
    "\n",
    "def mapper(item_index_list):\n",
    "    result = []\n",
    "    for item in item_index_list:\n",
    "        result.append(fin_dataset.iloc[item,1])\n",
    "    return result    \n",
    "    \n",
    "def intersection(lst1, lst2):\n",
    "    lst1.sort()\n",
    "    set2 = set(lst2)\n",
    "    common=0\n",
    "    for item in lst1:\n",
    "        if item in set2:\n",
    "            common += 1\n",
    "    return common/len(lst1)\n",
    "\n",
    "                          \n",
    "mean_items_bought = 0\n",
    "user_idx = shopsy_click_users['account_index'].unique()\n",
    "user_idx = sample(list(user_idx),500)\n",
    "print(\"Sampling done\")\n",
    "start_time = time.time()\n",
    "for user in user_idx:\n",
    "    count = count+1\n",
    "    item_interest = np.dot(item_vecs,x[user].reshape(-1, 1)).reshape(-1)\n",
    "    pred_items = (-item_interest).argsort()[:20]\n",
    "    actual_items = shopsy_click_users[shopsy_click_users['account_index']==user]\n",
    "    items_bought = actual_items['product_index'].unique()\n",
    "    frac_actually_bought = intersection(mapper(items_bought),mapper(pred_items))\n",
    "    mean_items_bought += frac_actually_bought \n",
    "mean_items_bought = mean_items_bought/len(user_idx)\n",
    "print(\"Mean item fraction brought: \",mean_items_bought)\n",
    "print(\"Time taken ->\", time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = kmeans.labels_\n",
    "centers = kmeans.cluster_centers_\n",
    "mean_items_bought = 0\n",
    "user_idx = shopsy_click_users['account_index'].unique()\n",
    "user_idx = sample(list(user_idx),250)\n",
    "print(\"Sampling done\")\n",
    "start_time = time.time()\n",
    "for user in user_idx:\n",
    "    cluster_item = np.dot(item_vecs,centers[labels[user]].reshape(-1,1)).reshape(-1)\n",
    "    pred_center = (-cluster_item).argsort()[:5]\n",
    "    item_interest = np.dot(item_vecs,x[user].reshape(-1, 1)).reshape(-1)\n",
    "    pred_items = (-item_interest).argsort()[:5]\n",
    "    frac_actually_bought = intersection(mapper(items_bought),mapper(pred_items))\n",
    "    mean_items_bought += frac_actually_bought \n",
    "mean_items_bought = mean_items_bought/len(user_idx)\n",
    "print(\"Mean item fraction brought: \",mean_items_bought)\n",
    "print(\"Time taken ->\", time.time() - start_time)  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in range(0,10):\n",
    "    if c==3 or c==4 or c==6 or c==8:\n",
    "        continue\n",
    "    cluster_index = np.where(labels==c)\n",
    "    mean_items_bought = 0\n",
    "    user_idx = cluster_index[0]\n",
    "    user_idx = sample(list(user_idx),250)\n",
    "    print(\"Sampling done\")\n",
    "    start_time = time.time()\n",
    "    cluster_item = np.dot(item_vecs,centers[c].reshape(-1,1)).reshape(-1)\n",
    "    pred_center = (-cluster_item).argsort()[:20]\n",
    "    for user in user_idx:    \n",
    "        item_interest = np.dot(item_vecs,x[user].reshape(-1, 1)).reshape(-1)\n",
    "        pred_items = (-item_interest).argsort()[:20]\n",
    "        frac_actually_bought = intersection(mapper(items_bought),mapper(pred_items))\n",
    "        mean_items_bought += frac_actually_bought \n",
    "    mean_items_bought = mean_items_bought/len(user_idx)\n",
    "    print(\"Mean item fraction brought: \",mean_items_bought)\n",
    "    print(\"Time taken ->\", time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccardian(lst1,lst2):\n",
    "    lst1.sort()\n",
    "    lst2.sort()\n",
    "    i = 0\n",
    "    j = 0\n",
    "    common = 0\n",
    "    while(i<len(lst1) and j<len(lst2)):\n",
    "        if(lst1[i]>lst2[j]):\n",
    "            j += 1\n",
    "        elif(lst1[i]<lst2[j]):\n",
    "            i += 1\n",
    "        else:\n",
    "            i += 1\n",
    "            j += 1\n",
    "            common += 1\n",
    "    return common/(len(lst1)+len(lst2) - common)\n",
    "            \n",
    "\n",
    "for c in range(0,10):\n",
    "    if c==3 or c==4 or c==6 or c==8:\n",
    "        continue\n",
    "    cluster_index = np.where(labels==c)\n",
    "    mean_items_bought = 0\n",
    "    user_idx = cluster_index[0]\n",
    "    user_idx_1 = sample(list(user_idx),250)\n",
    "    user_idx_2 = sample(list(user_idx),250)\n",
    "    start_time = time.time()\n",
    "    arr1 = []\n",
    "    print(\"Sampling done\")\n",
    "    for i in range(0,250):\n",
    "        item_interest = np.dot(item_vecs,x[user_idx_1[i]].reshape(-1, 1)).reshape(-1)\n",
    "        pred_items_1 = (-item_interest).argsort()[:20]\n",
    "        item_interest = np.dot(item_vecs,x[user_idx_2[i]].reshape(-1, 1)).reshape(-1)\n",
    "        pred_items_2 = (-item_interest).argsort()[:20]\n",
    "        arr1.append(jaccardian(mapper(pred_items_1),mapper(pred_items_2)))\n",
    "    mean_items_bought = np.mean(np.array(arr1))\n",
    "    print(\"Mean item fraction brought: \",mean_items_bought)\n",
    "    print(\"Time taken ->\", time.time() - start_time)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.shape)\n",
    "data_fin = data[data['count'] >5] \n",
    "print(data_fin.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
